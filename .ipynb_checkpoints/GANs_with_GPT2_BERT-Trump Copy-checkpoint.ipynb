{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T17:07:10.332576Z",
     "start_time": "2020-11-13T17:07:02.324009Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler, random_split\n",
    "torch.manual_seed(42)\n",
    "\n",
    "from transformers import pipelines\n",
    "from transformers import GPT2LMHeadModel,  GPT2Tokenizer, GPT2Config, GPT2LMHeadModel\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "from pymongo import MongoClient\n",
    "\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "import warnings\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T17:07:10.340577Z",
     "start_time": "2020-11-13T17:07:10.333575Z"
    }
   },
   "outputs": [],
   "source": [
    "# client = MongoClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T17:07:10.344575Z",
     "start_time": "2020-11-13T17:07:10.342576Z"
    }
   },
   "outputs": [],
   "source": [
    "# db = client['reviews']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T17:07:10.351578Z",
     "start_time": "2020-11-13T17:07:10.345576Z"
    }
   },
   "outputs": [],
   "source": [
    "# collection = db['reviews']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOOKMARK: get my own dataset for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Must make my own `reviews` df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_trump_tweets(fpath='trump_tweets.csv',append_date=True,\n",
    "                          verbose=True,return_data=True):\n",
    "    \"\"\"Downloads the most recent data from the trumptwittearchive v2.\n",
    "    https://drive.google.com/uc?export=download&id=1JZnhB0Nq_2RKtDb-IOnd0XxnD5c7x-nQ\n",
    "    \n",
    "    Args:\n",
    "        fpath (str): filepath for data that ends with .csv\n",
    "        append_date (bool): Whether to save today's date as part of filename(Default=True)\n",
    "        verbose (bool): Whether to print the file name (Default=True)\n",
    "        return_data (bool): Whether to return the data as a df (Default=True)\"\"\"\n",
    "#     url = \"https://www.thetrumparchive.com/latest-tweets\"        ## Import data downloading packages\n",
    "    import datetime as dt\n",
    "    import requests\n",
    "    import pandas as pd\n",
    "    import json\n",
    "\n",
    "    url=\"https://drive.google.com/uc?export=download&id=1JZnhB0Nq_2RKtDb-IOnd0XxnD5c7x-nQ\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if append_date:\n",
    "        suffix = \"_\"+dt.date.today().strftime('%m-%d-%y')\n",
    "        filepath = f\"{fpath.split('.')[0]}{suffix}.{fpath.split('.')[-1]}\"\n",
    "    else:\n",
    "        filepath=fpath\n",
    "        \n",
    "        \n",
    "    ## Save output to csv file\n",
    "    with open(filepath,'wb') as file:\n",
    "        file.write(response.content)  \n",
    "        \n",
    "#     with open(filepath,'w') as f:\n",
    "# #         f.write(response.content)\n",
    "#         f.write(json.dumps(response.json()))\n",
    "    \n",
    "#     if fpath.endswith('.csv'):\n",
    "#         tweets = pd.read_json(filepath)\n",
    "#         tweets.to_csv(filepath)\n",
    "#     else: \n",
    "#         tweets = pd.read_json(filepath)\n",
    "        \n",
    "    if verbose:\n",
    "        print('[i] Tweet data successfully downloaded and saved as:')\n",
    "        print('- ',filepath)\n",
    "        \n",
    "    if return_data:\n",
    "\n",
    "        return pd.read_csv(filepath,index_col=0,parse_dates=['date'])\n",
    "#tweets#,parse_dates=['created_at'])\n",
    "\n",
    "\n",
    "df = download_trump_tweets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collection = df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T17:07:10.998575Z",
     "start_time": "2020-11-13T17:07:10.352575Z"
    }
   },
   "outputs": [],
   "source": [
    "# test = []\n",
    "# ind = []\n",
    "\n",
    "# reviews = collection.find()\n",
    "\n",
    "# for index, review in enumerate(reviews[50000:75000]):\n",
    "#     try:\n",
    "#         test.append('{0}'.format(review['reviewText']))\n",
    "#     except KeyError:\n",
    "#         ind.append(index)\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T17:07:11.005577Z",
     "start_time": "2020-11-13T17:07:10.999575Z"
    }
   },
   "outputs": [],
   "source": [
    "# review_data = pd.DataFrame(data=test, columns=(['reviews']))\n",
    "# review_data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T17:07:11.020575Z",
     "start_time": "2020-11-13T17:07:11.006576Z"
    }
   },
   "outputs": [],
   "source": [
    "# review_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T17:07:11.029577Z",
     "start_time": "2020-11-13T17:07:11.022577Z"
    }
   },
   "outputs": [],
   "source": [
    "# review_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T17:07:11.035577Z",
     "start_time": "2020-11-13T17:07:11.031578Z"
    }
   },
   "outputs": [],
   "source": [
    "# reviews = review_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## JUST TRUMP\n",
    "df = df[df['isRetweet'] == 'f']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T17:07:11.040577Z",
     "start_time": "2020-11-13T17:07:11.036578Z"
    }
   },
   "outputs": [],
   "source": [
    "# reviews = reviews['reviews']\n",
    "reviews = df['text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T17:07:25.088807Z",
     "start_time": "2020-11-13T17:07:11.041577Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "tokenizer = nltk.TweetTokenizer()\n",
    "reviewlen = []\n",
    "for review in tqdm(reviews):\n",
    "\n",
    "    tokens = tokenizer.tokenize(review)#nltk.word_tokenize(review)\n",
    "    reviewlen.append(len(tokens))\n",
    "    \n",
    "reviewlen = np.array(reviewlen)\n",
    "\n",
    "sns.distplot(reviewlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T17:07:25.092805Z",
     "start_time": "2020-11-13T17:07:25.089808Z"
    }
   },
   "outputs": [],
   "source": [
    "len(reviewlen[reviewlen > 768])/len(reviewlen)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T17:07:25.098806Z",
     "start_time": "2020-11-13T17:07:25.093806Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Average review length: {} words.'.format(round(np.average(reviewlen), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T17:07:25.104806Z",
     "start_time": "2020-11-13T17:07:25.099805Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Max review length: {} words.'.format(np.max(reviewlen)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T17:07:25.742808Z",
     "start_time": "2020-11-13T17:07:25.105807Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2',\n",
    "                                          bos_token='<|sot|>', eos_token='<|eot|>', pad_token='<|pad|>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T17:07:25.746806Z",
     "start_time": "2020-11-13T17:07:25.743805Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Max model length is {} for this model\".format(tokenizer.model_max_length))\n",
    "print(\"Beginning of sentence token {} token has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.bos_token_id), tokenizer.bos_token_id))\n",
    "print(\"End of sentence token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.eos_token_id), tokenizer.eos_token_id))\n",
    "print(\"Padding token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.pad_token_id), tokenizer.pad_token_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T17:07:25.753808Z",
     "start_time": "2020-11-13T17:07:25.747806Z"
    }
   },
   "outputs": [],
   "source": [
    "class GPT_Finetune_Dataset(Dataset):\n",
    "\n",
    "  def __init__(self, txt_list, tokenizer, gpt2_type=\"gpt2\", max_length=200):\n",
    "\n",
    "    self.tokenizer = tokenizer\n",
    "    self.input = []\n",
    "    self.attn = []\n",
    "\n",
    "    for txt in tqdm(txt_list):\n",
    "\n",
    "      encodings_dict = tokenizer('<|sot|>'+ txt +'<|eot|>',\n",
    "                                 truncation=True, max_length=max_length, padding=\"max_length\")\n",
    "\n",
    "      self.input.append(torch.tensor(encodings_dict['input_ids']))\n",
    "      self.attn.append(torch.tensor(encodings_dict['attention_mask']))\n",
    "    \n",
    "  def __len__(self):\n",
    "    return len(self.input)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.input[idx], self.attn[idx] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T17:07:39.255919Z",
     "start_time": "2020-11-13T17:07:25.754807Z"
    }
   },
   "outputs": [],
   "source": [
    "data = GPT_Finetune_Dataset(reviews, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T17:07:39.261918Z",
     "start_time": "2020-11-13T17:07:39.256918Z"
    }
   },
   "outputs": [],
   "source": [
    "train_size = int(len(data) * .7)\n",
    "test_size = len(data) - train_size\n",
    "\n",
    "train_set, test_set = random_split(data, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T17:07:39.267917Z",
     "start_time": "2020-11-13T17:07:39.262917Z"
    }
   },
   "outputs": [],
   "source": [
    "print('{} training samples'.format(train_size))\n",
    "print('{} test samples'.format(test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T17:07:39.281918Z",
     "start_time": "2020-11-13T17:07:39.268916Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "train_dataloader = DataLoader(\n",
    "            train_set,  # The training set\n",
    "            sampler = RandomSampler(train_set), # Random sampler\n",
    "            batch_size = batch_size # Trains with this batch size for memory reasons\n",
    "        )\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "            test_set, # The validation samples.\n",
    "            sampler = SequentialSampler(test_set), # Pull out batches sequentially since order doesn't matter\n",
    "            batch_size = batch_size \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T17:07:39.292917Z",
     "start_time": "2020-11-13T17:07:39.283919Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T17:07:45.222480Z",
     "start_time": "2020-11-13T17:07:39.295917Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get config\n",
    "configuration = GPT2Config.from_pretrained('gpt2', output_hidden_states=False)\n",
    "\n",
    "# Model instantiation\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\", config=configuration)\n",
    "\n",
    "# Necessary because of the custom tokens\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Model to the GPU\n",
    "device = torch.device('cpu')#\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.cuda()\n",
    "\n",
    "seed_val = 42\n",
    "\n",
    "# Setting seeds\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T17:07:45.227477Z",
     "start_time": "2020-11-13T17:07:45.223477Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setting Parameters\n",
    "epochs = 5\n",
    "learning_rate = .001#.00005\n",
    "warmup_steps = 50\n",
    "\n",
    "# this produces sample output every 100 steps\n",
    "sample_every = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T17:07:45.234477Z",
     "start_time": "2020-11-13T17:07:45.228480Z"
    }
   },
   "outputs": [],
   "source": [
    "#AdamW is a class from the huggingface library that schedules weights\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = learning_rate\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T17:07:45.239480Z",
     "start_time": "2020-11-13T17:07:45.235477Z"
    }
   },
   "outputs": [],
   "source": [
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Adjusts the learning rate as the model steps through\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = warmup_steps, \n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T18:39:45.233263Z",
     "start_time": "2020-11-13T17:07:45.240477Z"
    }
   },
   "outputs": [],
   "source": [
    "timestat = time.time()\n",
    "\n",
    "stats = []\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "\n",
    "    # training loop\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "\n",
    "    timestat = time.time()\n",
    "\n",
    "    total_train_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_labels = batch[0].to(device)\n",
    "        b_masks = batch[1].to(device)\n",
    "\n",
    "        model.zero_grad()        \n",
    "\n",
    "        outputs = model(  b_input_ids,\n",
    "                          labels=b_labels, \n",
    "                          attention_mask = b_masks,\n",
    "                          token_type_ids=None\n",
    "                        )\n",
    "\n",
    "        loss = outputs[0]  \n",
    "\n",
    "        batch_loss = loss.item()\n",
    "        total_train_loss += batch_loss\n",
    "\n",
    "        # Get sample every x batches.\n",
    "        if step % sample_every == 0 and not step == 0:\n",
    "\n",
    "            elapsed = time.time() - timestat\n",
    "            print('  Batch {:>5,}  of  {:>5,}. Loss: {:>5,}.   Elapsed: {:}.'.format(step, len(train_dataloader), batch_loss, elapsed))\n",
    "\n",
    "            model.eval()\n",
    "\n",
    "            sample_outputs = model.generate(\n",
    "                                    bos_token_id=random.randint(1,30000),\n",
    "                                    do_sample=True,   \n",
    "                                    top_k=50, \n",
    "                                    max_length = 200,\n",
    "                                    top_p=0.95, \n",
    "                                    num_return_sequences=1\n",
    "                                )\n",
    "            for i, sample_output in enumerate(sample_outputs):\n",
    "                  print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))\n",
    "            \n",
    "            model.train()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)       \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = time.time() - timestat\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(training_time))\n",
    "\n",
    "    # Testing loop\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in test_dataloader:\n",
    "        \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_labels = batch[0].to(device)\n",
    "        b_masks = batch[1].to(device)\n",
    "        \n",
    "        with torch.no_grad():        \n",
    "\n",
    "            outputs  = model(b_input_ids, \n",
    "#                            token_type_ids=None, \n",
    "                             attention_mask = b_masks,\n",
    "                            labels=b_labels)\n",
    "          \n",
    "            loss = outputs[0]  \n",
    "            \n",
    "        batch_loss = loss.item()\n",
    "        total_eval_loss += batch_loss        \n",
    "\n",
    "    avg_val_loss = total_eval_loss / len(test_dataloader)\n",
    "    \n",
    "    validation_time = time.time() - timestat \n",
    "\n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T18:39:45.293263Z",
     "start_time": "2020-11-13T18:39:45.250263Z"
    }
   },
   "outputs": [],
   "source": [
    "training_df = pd.DataFrame(data=stats)\n",
    "\n",
    "training_df = training_df.set_index('epoch')\n",
    "\n",
    "training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T19:31:45.046163Z",
     "start_time": "2020-11-13T19:31:44.924162Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "plt.plot(training_df['Training Loss'], 'r-o', label=\"Training\")\n",
    "plt.plot(training_df['Valid. Loss'], 'b-o', label=\"Testing\")\n",
    "plt.title(\"Training & Testing Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.xticks([1, 2, 3, 4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T19:44:13.346877Z",
     "start_time": "2020-11-13T19:44:13.343876Z"
    }
   },
   "outputs": [],
   "source": [
    "params = list(model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T19:45:54.186803Z",
     "start_time": "2020-11-13T19:45:54.181805Z"
    }
   },
   "outputs": [],
   "source": [
    "# for param in params:\n",
    "#     print(param[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T19:48:42.171694Z",
     "start_time": "2020-11-13T19:48:42.166693Z"
    }
   },
   "outputs": [],
   "source": [
    "output_dir = './model_save/'\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T19:49:20.881724Z",
     "start_time": "2020-11-13T19:49:20.878724Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Saving model to {}\".format(output_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T19:52:16.026553Z",
     "start_time": "2020-11-13T19:52:14.581877Z"
    }
   },
   "outputs": [],
   "source": [
    "model_to_save = model.module if hasattr(model, 'module') else model\n",
    "model_to_save.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOOKMARK: MAKING PROMPTS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T21:06:15.875080Z",
     "start_time": "2020-11-13T21:06:15.872081Z"
    }
   },
   "outputs": [],
   "source": [
    "prompts = []\n",
    "for review in reviews[:15]:\n",
    "    try:\n",
    "        prompts.append(\"<|sot|> \" + ' '.join(review.split()))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T21:06:16.307080Z",
     "start_time": "2020-11-13T21:06:16.303081Z"
    }
   },
   "outputs": [],
   "source": [
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T21:07:55.776054Z",
     "start_time": "2020-11-13T21:07:55.760054Z"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "gen_prompt = []\n",
    "for prompt in prompts:\n",
    "    gen_prompt.append(torch.tensor(tokenizer.encode(prompt)).unsqueeze(0).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T21:41:17.055828Z",
     "start_time": "2020-11-13T21:39:28.822830Z"
    }
   },
   "outputs": [],
   "source": [
    "for x, promp in enumerate(gen_prompt):\n",
    "    print('---------------------------------')\n",
    "    print('''The prompt is \"{}\"'''.format(prompts[x]))\n",
    "    print('---------------------------------')\n",
    "    sample_outputs = model.generate(\n",
    "                                    promp, \n",
    "                                    bos_token_id= random.randint(1, 100000),\n",
    "                                    do_sample=True,   \n",
    "                                    top_k=30, \n",
    "                                    min_length=20,\n",
    "                                    max_length = 40,\n",
    "                                    top_p=0.95,\n",
    "                                    num_return_sequences=5\n",
    "                                    )\n",
    "\n",
    "    for i, sample_output in enumerate(sample_outputs):\n",
    "      print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "305.455px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
